# Deep Learning for Natural Language Processing Cheatsheet
Cheatsheet for the lecture Deep Learning for Natural Language Processing at TU Darmstadt. Content and figures are mainly taken from the course repositors ([deep-learning-for-nlp-lectures](https://github.com/dl4nlp-tuda2021/deep-learning-for-nlp-lectures)), published under the  [Creative Commons CC BY-SA 4.0 license](https://creativecommons.org/licenses/by-sa/4.0/).

If you find any errors or you want to add something, feel free to raise an issue.

# References

Additional references of figures and content.

```bibtex
@inproceedings{Vaswani2017,
    title={{Attention Is All You Need}},
    author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
    booktitle={{Advances in Neural Information Processing Systems}},
    pages={5998--6008},
    year={2017}
}
```

```bibtex
@inproceedings{Reimers2019,
    title={{Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks}},
    author={Reimers, Nils and Gurevych, Iryna},
    booktitle={{Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing}},
    year={2019},
    organization={{Association for Computational Linguistics}}
}
```

```bibtex
@inproceedings{Devlin2019,
    title={{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}},
    author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
    booktitle={NAACL-HLT},
    year={2019}
}
```
